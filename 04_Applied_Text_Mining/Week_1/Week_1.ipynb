{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data. \n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates. \n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "* 6/2008; 12/2009\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices.\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         03/25/93 Total time of visit (in minutes):\\n\n",
       "1                       6/18/85 Primary Care Doctor:\\n\n",
       "2    sshe plans to move as of 7/8/71 In-Home Servic...\n",
       "3                7 on 9/27/75 Audit C Score Current:\\n\n",
       "4    2/6/96 sleep studyPain Treatment Pain Level (N...\n",
       "5                    .Per 7/06/79 Movement D/O note:\\n\n",
       "6    4, 5/18/78 Patient's thoughts about current su...\n",
       "7    10/24/89 CPT Code: 90801 - Psychiatric Diagnos...\n",
       "8                         3/7/86 SOS-10 Total Score:\\n\n",
       "9             (4/10/71)Score-1Audit C Score Current:\\n\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc = []\n",
    "with open('dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "df = pd.Series(doc)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate Regex to extract Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150     [12 March 1980]\n",
       "151      [22 June 1990]\n",
       "152       [28 Sep 2015]\n",
       "153       [13 Jan 1972]\n",
       "154       [06 Mar 1974]\n",
       "155       [10 Oct 1974]\n",
       "156       [26 May 1974]\n",
       "157       [10 Feb 1990]\n",
       "158       [23 Aug 2000]\n",
       "159       [26 May 2001]\n",
       "160       [21 Oct 2007]\n",
       "161       [19 Oct 2016]\n",
       "162       [05 Mar 1974]\n",
       "163       [29 Jan 1994]\n",
       "164       [21 Oct 1978]\n",
       "165    [18 August 1975]\n",
       "166       [11 Nov 1996]\n",
       "167       [01 Oct 1979]\n",
       "168       [13 Oct 1986]\n",
       "169       [21 Oct 1995]\n",
       "170       [24 Jan 2011]\n",
       "171       [04 Oct 1972]\n",
       "172       [23 Aug 1993]\n",
       "173       [18 Oct 2006]\n",
       "174       [04 Dec 1988]\n",
       "175       [21 Oct 1983]\n",
       "176       [26 May 2010]\n",
       "177       [18 Jan 1990]\n",
       "178       [15 Jun 1985]\n",
       "179       [10 Dec 1982]\n",
       "180       [09 Dec 1988]\n",
       "181    [18 August 1995]\n",
       "182      [13 June 1974]\n",
       "183       [26 May 2008]\n",
       "184       [11 Nov 2002]\n",
       "185       [17 Aug 1985]\n",
       "186       [13 Oct 2016]\n",
       "187       [14 Jan 2008]\n",
       "188     [12 March 2004]\n",
       "189       [21 Oct 1977]\n",
       "190       [10 Aug 2000]\n",
       "191       [30 Nov 1972]\n",
       "192       [06 May 1993]\n",
       "193       [18 Jan 1995]\n",
       "194                  []\n",
       "195                  []\n",
       "196                  []\n",
       "197                  []\n",
       "198                  []\n",
       "199                  []\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from 1 to 193\n",
    "df.str.findall('\\d{1,2}[-/ ](?:\\d{1,2}|Jan[A-Za-z]*|Feb[A-Za-z]*|Mar[A-Za-z]*|Apr[A-Za-z]*|May[A-Za-z]*|' +\n",
    "               'Jun[A-Za-z]*|Jul[A-Za-z]*|Aug[A-Za-z]*|Sep[A-Za-z]*|Oct[A-Za-z]*|Nov[A-Za-z]*|Dec[A-Za-z]*)' + \n",
    "               '[-/ ](?:\\d{2}|\\d{4})(?!\\d)').head(200).tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300      [January 1994]\n",
       "301          [Dec 1992]\n",
       "302     [November 2004]\n",
       "303      [January 1977]\n",
       "304          [Mar 2002]\n",
       "305          [Feb 2000]\n",
       "306         [May, 2004]\n",
       "307         [July 2006]\n",
       "308          [Feb 1994]\n",
       "309        [April 1977]\n",
       "310          [Oct 1992]\n",
       "311    [February, 1995]\n",
       "312     [February 1989]\n",
       "313    [Decemeber 1978]\n",
       "314      [January 2007]\n",
       "315          [Jun 1976]\n",
       "316          [May 2011]\n",
       "317         [Mar, 1975]\n",
       "318          [Jan 1978]\n",
       "319         [July 1975]\n",
       "320     [November 2012]\n",
       "321        [June, 1999]\n",
       "322      [October 1991]\n",
       "323        [March 1973]\n",
       "324      [October 1996]\n",
       "325          [Jun 2007]\n",
       "326      [October 1995]\n",
       "327        [April 1999]\n",
       "328         [May, 2001]\n",
       "329       [March, 2000]\n",
       "330        [April 1988]\n",
       "331     [December 1993]\n",
       "332         [June 1974]\n",
       "333     [November 1997]\n",
       "334         [July 1986]\n",
       "335     [February 1973]\n",
       "336        [March 1978]\n",
       "337          [Dec 2007]\n",
       "338         [Apr, 1998]\n",
       "339       [March, 2005]\n",
       "340          [May 1980]\n",
       "341          [Nov 2007]\n",
       "342        [March 1976]\n",
       "343                  []\n",
       "344                  []\n",
       "345                  []\n",
       "346                  []\n",
       "347                  []\n",
       "348                  []\n",
       "349                  []\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from 194 to 342\n",
    "df.str.findall('(?:Jan[A-Za-z.]*|Feb[A-Za-z.]*|Mar[A-Za-z.]*|Apr[A-Za-z.]*|May[A-Za-z.]*|Jun[A-Za-z.]*|' +\n",
    "               'Jul[A-Za-z.]*|Aug[A-Za-z.]*|Sep[A-Za-z.]*|Oct[A-Za-z.]*|Nov[A-Za-z.]*|Dec[A-Za-z.]*)' + \n",
    "               '[ ]?(?:\\d{0}|\\d{2})[,.]? (?:\\d{2}|\\d{4})(?!\\d)').head(350).tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450     [1/1994]\n",
       "451    [12/2004]\n",
       "452     [3/2003]\n",
       "453     [7/1991]\n",
       "454     [7/1982]\n",
       "455       [1984]\n",
       "456       [2000]\n",
       "457       [2001]\n",
       "458       [1982]\n",
       "459       [1998]\n",
       "460       [2012]\n",
       "461       [1991]\n",
       "462       [1988]\n",
       "463       [2014]\n",
       "464       [2016]\n",
       "465       [1976]\n",
       "466       [1981]\n",
       "467       [2011]\n",
       "468       [1997]\n",
       "469       [2003]\n",
       "470       [1983]\n",
       "471       [1999]\n",
       "472       [2010]\n",
       "473       [1975]\n",
       "474       [1972]\n",
       "475       [2015]\n",
       "476       [1989]\n",
       "477       [1994]\n",
       "478       [1993]\n",
       "479       [1996]\n",
       "480       [2013]\n",
       "481       [1974]\n",
       "482       [1990]\n",
       "483       [1995]\n",
       "484       [2004]\n",
       "485       [1987]\n",
       "486       [1973]\n",
       "487       [1992]\n",
       "488       [1977]\n",
       "489       [1985]\n",
       "490       [2007]\n",
       "491       [2009]\n",
       "492       [1986]\n",
       "493       [1978]\n",
       "494       [2002]\n",
       "495       [1979]\n",
       "496       [2006]\n",
       "497       [2008]\n",
       "498       [2005]\n",
       "499       [1980]\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from 343 to 500\n",
    "df.str.findall('\\d{0,2}/?\\d{4}').head(500).tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply regex, clean dates and sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser as parser\n",
    "import datetime\n",
    "\n",
    "def date_sorter():\n",
    "    \n",
    "    # Define regex to extract dates in different format\n",
    "    \n",
    "    regex_1 =  '\\d{1,2}[-/ ](?:\\d{1,2}|Jan[A-Za-z]*|Feb[A-Za-z]*|Mar[A-Za-z]*|Apr[A-Za-z]*|May[A-Za-z]*|'     + \\\n",
    "               'Jun[A-Za-z]*|Jul[A-Za-z]*|Aug[A-Za-z]*|Sep[A-Za-z]*|Oct[A-Za-z]*|Nov[A-Za-z]*|Dec[A-Za-z]*)' + \\\n",
    "               '[-/ ](?:\\d{2}|\\d{4})(?!\\d)'\n",
    "            \n",
    "    regex_2 =  '(?:Jan[A-Za-z.]*|Feb[A-Za-z.]*|Mar[A-Za-z.]*|Apr[A-Za-z.]*|May[A-Za-z.]*|Jun[A-Za-z.]*|' + \\\n",
    "               'Jul[A-Za-z.]*|Aug[A-Za-z.]*|Sep[A-Za-z.]*|Oct[A-Za-z.]*|Nov[A-Za-z.]*|Dec[A-Za-z.]*)'   + \\\n",
    "               '[ ]?(?:\\d{0}|\\d{2})[,.]? (?:\\d{2}|\\d{4})(?!\\d)'\n",
    "            \n",
    "    regex_3 = '\\d{0,2}/?\\d{4}'\n",
    "    \n",
    "    # Apply regex to each of the three buckets and concat\n",
    "    dates = df.iloc[:194].str.findall(regex_1)\n",
    "    dates = pd.concat([dates, df.iloc[194:343].str.findall(regex_2)])\n",
    "    dates = pd.concat([dates, df.iloc[343:].str.findall(regex_3)])\n",
    "    \n",
    "    # Convert each elemnt from list to string\n",
    "    dates = dates.apply(lambda x: x[0])\n",
    "    \n",
    "    # Clean typos\n",
    "    dates = dates.str.replace('Janaury', 'January')\n",
    "    dates = dates.str.replace('Decemeber', 'December')\n",
    "    \n",
    "    # Convert from string to datetime \n",
    "    dates = dates.apply(lambda x: parser.parse(x, default = datetime.datetime(2020, 1, 1, 0, 0)))\n",
    "    \n",
    "    # Sort dates and return indexes\n",
    "    sorted_indexes = dates.sort_values(ascending = True).index.values\n",
    "    \n",
    "    return pd.Series(sorted_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9\n",
       "1       84\n",
       "2        2\n",
       "3       53\n",
       "4       28\n",
       "5      474\n",
       "6      153\n",
       "7       13\n",
       "8      129\n",
       "9       98\n",
       "10     111\n",
       "11     225\n",
       "12      31\n",
       "13     171\n",
       "14     191\n",
       "15     486\n",
       "16     335\n",
       "17     415\n",
       "18      36\n",
       "19     405\n",
       "20     323\n",
       "21     422\n",
       "22     375\n",
       "23     380\n",
       "24     345\n",
       "25      57\n",
       "26     481\n",
       "27     436\n",
       "28     104\n",
       "29     299\n",
       "      ... \n",
       "470    220\n",
       "471    208\n",
       "472    243\n",
       "473    139\n",
       "474    320\n",
       "475    383\n",
       "476    244\n",
       "477    286\n",
       "478    480\n",
       "479    431\n",
       "480    279\n",
       "481    198\n",
       "482    381\n",
       "483    463\n",
       "484    366\n",
       "485    439\n",
       "486    255\n",
       "487    401\n",
       "488    475\n",
       "489    257\n",
       "490    152\n",
       "491    235\n",
       "492    464\n",
       "493    253\n",
       "494    427\n",
       "495    231\n",
       "496    141\n",
       "497    186\n",
       "498    161\n",
       "499    413\n",
       "Length: 500, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_sorter()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
